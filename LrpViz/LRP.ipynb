{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer-wise Relevance Propagation  for sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input\n",
    "from keras.layers import RNN,Lambda,Dense,Bidirectional,Add,LSTM,Layer,Concatenate,Masking,Dropout,InputLayer\n",
    "from keras import Model\n",
    "\n",
    "import keras\n",
    "from keras.utils.generic_utils import CustomObjectScope\n",
    "\n",
    "import os,sys\n",
    "from os.path import dirname, join, abspath\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "UTILS_DIR = '../common_utils/'\n",
    "sys.path.insert(0, abspath(join(dirname(UTILS_DIR), '.')))\n",
    "from LRP_utils import LRP_LSTMCell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading pretrained sentiment model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKING_DIR = os.getcwd()\n",
    "PATH = WORKING_DIR +'/models/bi_lstm_model.pickle'\n",
    "\n",
    "hid_dim = embd_dim = dim = 60\n",
    "n_classes = 5\n",
    "with open(PATH,'rb') as m:\n",
    "    pretrained_weights  = pickle.load(m)\n",
    "\n",
    "f_W = pretrained_weights['left_encoder_weights']['Wxh_Left'].transpose()\n",
    "f_U = pretrained_weights['left_encoder_weights']['Whh_Left'].transpose()\n",
    "f_b = pretrained_weights['left_encoder_weights']['bxh_Left'] + pretrained_weights['left_encoder_weights']['bhh_Left']\n",
    "\n",
    "f_W[:,dim:2*dim],f_W[:,2*dim:3*dim]= f_W[:,2*dim:3*dim].copy(),f_W[:,dim:2*dim].copy()\n",
    "f_U[:,dim:2*dim],f_U[:,2*dim:3*dim]= f_U[:,2*dim:3*dim].copy(),f_U[:,dim:2*dim].copy()\n",
    "f_b[dim:2*dim],f_b[2*dim:3*dim]= f_b[2*dim:3*dim].copy(),f_b[dim:2*dim].copy()\n",
    "\n",
    "b_W = pretrained_weights['right_encoder_weights']['Wxh_Right'].transpose()\n",
    "b_U = pretrained_weights['right_encoder_weights']['Whh_Right'].transpose()\n",
    "b_b = pretrained_weights['right_encoder_weights']['bxh_Right'] + pretrained_weights['right_encoder_weights']['bhh_Right']\n",
    "\n",
    "\n",
    "b_W[:,dim:2*dim],b_W[:,2*dim:3*dim]= b_W[:,2*dim:3*dim].copy(),b_W[:,dim:2*dim].copy()\n",
    "b_U[:,dim:2*dim],b_U[:,2*dim:3*dim]= b_U[:,2*dim:3*dim].copy(),b_U[:,dim:2*dim].copy()\n",
    "b_b[dim:2*dim],b_b[2*dim:3*dim]= b_b[2*dim:3*dim].copy(),b_b[dim:2*dim].copy()\n",
    "\n",
    "f_out = pretrained_weights['output_weights']['Why_Left'].transpose()\n",
    "b_out = pretrained_weights['output_weights']['Why_Right'].transpose()\n",
    "\n",
    "out = np.concatenate((f_out,b_out))\n",
    "b = np.zeros(n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, 60)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 120)               58080     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 605       \n",
      "=================================================================\n",
      "Total params: 58,685\n",
      "Trainable params: 58,685\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with CustomObjectScope({'LRP_LSTMCell': LRP_LSTMCell}):\n",
    "    cell = LRP_LSTMCell(60,recurrent_activation='sigmoid',implementation=1)\n",
    "    x = keras.Input((None,60))\n",
    "    bi_lstm = Bidirectional(RNN(cell))\n",
    "    h = bi_lstm(x)\n",
    "    y= Dense(5)(h)\n",
    "    model = Model(inputs=[x], outputs=[y])\n",
    "model.set_weights([f_W, f_U, f_b, b_W, b_U, b_b, out, b])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.83815783  0.55615956 -0.2387495   0.06664614 -0.4852757 ]\n",
      " [ 1.7834715   1.8099647   0.25141034 -1.1962156  -2.483652  ]]\n"
     ]
    }
   ],
   "source": [
    "embd_path = WORKING_DIR + '/embeddings/embeddings.npy'\n",
    "E = np.load(embd_path, mmap_mode='r')\n",
    "\n",
    "with open(WORKING_DIR+'/embeddings/vocab.dms','rb') as f_voc:\n",
    "    voc  = pickle.load(f_voc)\n",
    "    f_voc.close()\n",
    "    \n",
    "text_0        = ['i','hate','the','movie','though','the','plot','is','interesting','.']\n",
    "text_indeces_0 = [voc.index(w) for w in text_0]\n",
    "text_1 = 'i love the movie though it is so boring .'.split(' ')\n",
    "text_indeces_1 = [voc.index(w) for w in text_1]\n",
    "\n",
    "data1 = E[text_indeces_0].reshape((1,len(text_0),dim))\n",
    "data2 = E[text_indeces_1].reshape((1,len(text_1),dim))\n",
    "data = np.vstack((data1,data2))\n",
    "print(model.predict([data]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform LRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LRP_utils import get_target_activation\n",
    "from LRP_utils import cashe_lstm_forward_activations_batch\n",
    "from LRP_utils import lrp_dense_batch,lrp_lstm_batch\n",
    "eps=0.001\n",
    "bias_factor=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_1 local diff:  -2.4947244092743404e-07\n",
      "bidirectional_1 local diff:  4.489909415400581\n"
     ]
    }
   ],
   "source": [
    "all_activations = {}\n",
    "bi_lstm_layer = model.layers[1]#bi-LSTM\n",
    "dense_layer = model.layers[-1]\n",
    "all_activations[bi_lstm_layer.name] = cashe_lstm_forward_activations_batch(bi_lstm_layer, data,bidirectional=True,dim=dim)\n",
    "all_activations[dense_layer.name] = get_target_activation(dense_layer.input,dense_layer.output,all_activations[bi_lstm_layer.name]['final'])\n",
    "\n",
    "hin = all_activations[bi_lstm_layer.name]['final']\n",
    "w , b = dense_layer.get_weights()\n",
    "hout = all_activations[dense_layer.name][0]#.flatten()\n",
    "bias_nb_units = w.shape[0]\n",
    "\n",
    "Rout_mask = np.zeros_like(hout)\n",
    "Rout_mask[0,0] = 1\n",
    "Rout_mask[1,1] = 1\n",
    "#Rout_mask[1,LRP_CLASS] = 1\n",
    "viz_dense = lrp_dense_batch(hin, w, b, hout, hout*Rout_mask, bias_nb_units, eps, bias_factor, dense_layer.name, debug=True)\n",
    "\n",
    "\n",
    "hin = data\n",
    "Rout_Left_last = viz_dense[:,:dim].copy()\n",
    "Rout_Right_last = viz_dense[:,dim:].copy()\n",
    "\n",
    "seq_len = hin.shape[1]\n",
    "hidden_dim = dim\n",
    "input_dim = dim\n",
    "batch = data.shape[0]\n",
    "lstm_w = bi_lstm.get_weights()\n",
    "layer_name = bi_lstm_layer.name\n",
    "Rx = lrp_lstm_batch(all_activations, hin, Rout_Left_last, batch, seq_len, hidden_dim, input_dim, lstm_w, True, layer_name, Rout_Right_last, eps, bias_factor, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = np.sum(Rx,axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Saliency heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#fcfcff\">i</span> <span style=\"background-color:#ff8a8a\">hate</span> <span style=\"background-color:#fcfcff\">the</span> <span style=\"background-color:#fff6f6\">movie</span> <span style=\"background-color:#ffe0e0\">though</span> <span style=\"background-color:#fefeff\">the</span> <span style=\"background-color:#ffa8a8\">plot</span> <span style=\"background-color:#d0d0ff\">is</span> <span style=\"background-color:#0000ff\">interesting</span> <span style=\"background-color:#eaeaff\">.</span> \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#e2e2ff\">i</span> <span style=\"background-color:#7171ff\">love</span> <span style=\"background-color:#fefeff\">the</span> <span style=\"background-color:#f0f0ff\">movie</span> <span style=\"background-color:#ffeeee\">though</span> <span style=\"background-color:#fafaff\">it</span> <span style=\"background-color:#f6f6ff\">is</span> <span style=\"background-color:#eaeaff\">so</span> <span style=\"background-color:#ff0000\">boring</span> <span style=\"background-color:#dcdcff\">.</span> \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "from heatmap import html_heatmap\n",
    "\n",
    "display(HTML(html_heatmap(text_0, R[0])))\n",
    "display(HTML(html_heatmap(text_1, R[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
